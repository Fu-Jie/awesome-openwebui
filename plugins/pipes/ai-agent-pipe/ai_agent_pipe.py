"""
title: AI Agent Pipe
icon_url: data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCI+CiAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iMyIvPgogIDxwYXRoIGQ9Im0xMiA5IDAgNSIvPgogIDxwYXRoIGQ9Im0xMiAxNSAwIDUiLz4KICA8cGF0aCBkPSJtOSA5IDMgMyIvPgogIDxwYXRoIGQ9Im0xNSA5LTMgMyIvPgogIDxwYXRoIGQ9Im05IDE1IDMgMyIvPgogIDxwYXRoIGQ9Im0xNSAxNUwzIDMiLz4KPC9zdmc+
version: 1.0.0
description: AIä»£ç†ç®¡é“æ’ä»¶ï¼Œè®©AIå“åº”å±•ç¤ºå®Œæ•´çš„ä»£ç†å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬å¤šè½®æ€è€ƒã€å·¥å…·è°ƒç”¨å’Œè¿­ä»£åˆ†æã€‚
"""

from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
import logging
import json
from fastapi import Request

from open_webui.utils.chat import generate_chat_completion

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)


class Pipe:
    class Valves(BaseModel):
        priority: int = Field(
            default=0, description="Priority level for the pipe operations."
        )
        enable_agent_mode: bool = Field(
            default=True, description="Enable agent mode for all responses."
        )
        pass

    def __init__(self):
        self.valves = self.Valves()
        pass

    async def pipe(
        self,
        body: dict,
        __user__: Optional[dict] = {},
        __event_emitter__=None,
        __event_call__=None,
        __model__=None,
        __request__: Request = None,
    ) -> Optional[dict]:
        """
        AI Agent Pipe - Transform LLM responses into agent-style multi-step analysis
        """
        logger.info("AI Agent Pipe processing response")

        if not self.valves.enable_agent_mode:
            return body

        # è·å–åŸå§‹å“åº”
        messages = body.get("messages", [])
        if not messages:
            return body

        # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å’ŒAIå“åº”
        user_message = None
        ai_response = None

        for msg in reversed(messages):
            if msg.get("role") == "user" and not user_message:
                user_message = msg.get("content", "")
            elif msg.get("role") == "assistant" and not ai_response:
                ai_response = msg.get("content", "")

        if not user_message or not ai_response:
            return body

        # ç³»ç»Ÿæç¤ºï¼šè®©AIæ¨¡æ‹Ÿå®Œæ•´çš„ä»£ç†å·¥ä½œæµç¨‹
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªé«˜çº§AIä»£ç†ï¼Œèƒ½å¤Ÿè¿›è¡Œå¤šè½®æ€è€ƒã€å·¥å…·è°ƒç”¨å’Œè¿­ä»£åˆ†æã€‚è¯·æ¨¡æ‹Ÿä¸€ä¸ªå®Œæ•´çš„ä»£ç†å·¥ä½œæµç¨‹ï¼ŒåŒ…æ‹¬ï¼š

1. **åˆå§‹åˆ†æ**ï¼šç†è§£ç”¨æˆ·é—®é¢˜
2. **å¤šè½®æ€è€ƒ**ï¼šè¿›è¡Œæ·±å…¥åˆ†æå’Œæ¨ç†
3. **å·¥å…·è°ƒç”¨**ï¼šé€‰æ‹©å¹¶ä½¿ç”¨é€‚å½“çš„å·¥å…·
4. **ç»“æœå¤„ç†**ï¼šåˆ†æå·¥å…·è¿”å›çš„ç»“æœ
5. **æœ€ç»ˆæ€»ç»“**ï¼šæä¾›å®Œæ•´çš„è§£å†³æ–¹æ¡ˆ

è¯·ä»¥JSONæ ¼å¼è¿”å›å®Œæ•´çš„ä»£ç†å·¥ä½œæµç¨‹ï¼š

{
  "agent_workflow": [
    {
      "step": 1,
      "type": "thinking",
      "content": "åˆå§‹æ€è€ƒå†…å®¹"
    },
    {
      "step": 2,
      "type": "tool_call",
      "tool_name": "å·¥å…·åç§°",
      "tool_input": "å·¥å…·è¾“å…¥å‚æ•°",
      "reasoning": "ä¸ºä»€ä¹ˆä½¿ç”¨è¿™ä¸ªå·¥å…·"
    },
    {
      "step": 3,
      "type": "tool_result",
      "tool_output": "å·¥å…·è¿”å›çš„ç»“æœ",
      "analysis": "å¯¹ç»“æœçš„åˆ†æ"
    },
    {
      "step": 4,
      "type": "thinking",
      "content": "åŸºäºå·¥å…·ç»“æœçš„è¿›ä¸€æ­¥æ€è€ƒ"
    },
    {
      "step": 5,
      "type": "tool_call",
      "tool_name": "å¦ä¸€ä¸ªå·¥å…·",
      "tool_input": "æ–°çš„å·¥å…·è¾“å…¥",
      "reasoning": "ç»§ç»­æ·±å…¥åˆ†æ"
    }
  ],
  "final_answer": "æœ€ç»ˆçš„å®Œæ•´ç­”æ¡ˆ",
  "tools_used": ["ä½¿ç”¨çš„å·¥å…·åˆ—è¡¨"],
  "confidence_level": "ç½®ä¿¡åº¦è¯„ä¼°"
}

è‡³å°‘åŒ…å«3-5ä¸ªæ­¥éª¤çš„å®Œæ•´å·¥ä½œæµç¨‹ï¼Œå±•ç¤ºå‡ºä»£ç†çš„æ€è€ƒè¿‡ç¨‹å’Œå·¥å…·ä½¿ç”¨ã€‚
        """

        analysis_prompt = f"""
ç”¨æˆ·é—®é¢˜ï¼š{user_message}

è¯·ä½œä¸ºAIä»£ç†å®Œæ•´è§£å†³è¿™ä¸ªé—®é¢˜ã€‚å±•ç¤ºä½ çš„æ€è€ƒè¿‡ç¨‹ã€å·¥å…·ä½¿ç”¨å’Œæœ€ç»ˆç­”æ¡ˆã€‚

æ¨¡æ‹Ÿå¯ç”¨çš„å·¥å…·ï¼š
- web_search: ç½‘ç»œæœç´¢å·¥å…·
- code_analyzer: ä»£ç åˆ†æå·¥å…·
- data_processor: æ•°æ®å¤„ç†å·¥å…·
- knowledge_base: çŸ¥è¯†åº“æŸ¥è¯¢å·¥å…·
- calculator: è®¡ç®—å·¥å…·
- file_reader: æ–‡ä»¶è¯»å–å·¥å…·

è¯·è¿›è¡Œå¤šè½®æ€è€ƒå’Œå·¥å…·è°ƒç”¨æ¥å½»åº•è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
        """

        try:
            # è°ƒç”¨LLMè¿›è¡Œä»£ç†å¼åˆ†æ
            response = await generate_chat_completion(
                model=__model__,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": analysis_prompt},
                ],
                user=__user__,
            )

            # è§£æåˆ†æç»“æœ
            analysis_content = (
                response.get("choices", [{}])[0].get("message", {}).get("content", "")
            )

            try:
                analysis_result = json.loads(analysis_content)

                # æ„å»ºå¢å¼ºçš„å“åº”ï¼Œå±•ç¤ºå®Œæ•´çš„ä»£ç†å·¥ä½œæµç¨‹
                workflow_steps = analysis_result.get("agent_workflow", [])

                workflow_display = ""
                for step in workflow_steps:
                    step_num = step.get("step", 0)
                    step_type = step.get("type", "unknown")

                    if step_type == "thinking":
                        workflow_display += f"""
### ğŸ¤” æ€è€ƒæ­¥éª¤ {step_num}
{step.get('content', '')}
"""
                    elif step_type == "tool_call":
                        workflow_display += f"""
### ğŸ› ï¸ å·¥å…·è°ƒç”¨ {step_num}
**å·¥å…·ï¼š** {step.get('tool_name', '')}
**è¾“å…¥ï¼š** {step.get('tool_input', '')}
**åŸå› ï¼š** {step.get('reasoning', '')}
"""
                    elif step_type == "tool_result":
                        workflow_display += f"""
### ğŸ“Š å·¥å…·ç»“æœ {step_num}
**è¾“å‡ºï¼š** {step.get('tool_output', '')}
**åˆ†æï¼š** {step.get('analysis', '')}
"""

                enhanced_response = f"""
## ğŸ¤– AIä»£ç†å®Œæ•´å·¥ä½œæµç¨‹

### ğŸ¯ é—®é¢˜
{user_message}

{workflow_display}

### ğŸ‰ æœ€ç»ˆç­”æ¡ˆ
{analysis_result.get('final_answer', 'æ— æ³•è·å–æœ€ç»ˆç­”æ¡ˆ')}

### ğŸ“‹ ä½¿ç”¨å·¥å…·
{chr(10).join(f"â€¢ {tool}" for tool in analysis_result.get('tools_used', []))}

### ğŸ“Š ç½®ä¿¡åº¦
{analysis_result.get('confidence_level', 'æœªè¯„ä¼°')}
                """

                # æ›´æ–°æ¶ˆæ¯ä¸­çš„AIå“åº”
                for msg in messages:
                    if msg.get("role") == "assistant":
                        msg["content"] = enhanced_response
                        break

                body["messages"] = messages

            except json.JSONDecodeError:
                # å¦‚æœè§£æå¤±è´¥ï¼Œæ·»åŠ ç®€å•çš„ä»£ç†æ ¼å¼
                enhanced_response = f"""
## ğŸ¤– AIä»£ç†å“åº”

### åŸå§‹å›ç­”
{ai_response}

### ä»£ç†åˆ†æ
æ­¤å“åº”å·²é€šè¿‡AIä»£ç†ç®¡é“å¤„ç†ï¼ŒåŒ…å«å¤šè½®æ€è€ƒå’Œå·¥å…·è°ƒç”¨æ¨¡æ‹Ÿã€‚
                """

                for msg in messages:
                    if msg.get("role") == "assistant":
                        msg["content"] = enhanced_response
                        break

                body["messages"] = messages

        except Exception as e:
            logger.error(f"Error in AI Agent Pipe: {str(e)}")
            # å¦‚æœå‡ºé”™ï¼Œè¿”å›åŸå§‹body
            pass

        return body
