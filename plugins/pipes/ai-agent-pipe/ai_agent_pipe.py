"""
title: AI Agent Pipe
icon_url: data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIyNCIgaGVpZ2h0PSIyNCIgdmlld0JveD0iMCAwIDI0IDI0IiBmaWxsPSJub25lIiBzdHJva2U9ImN1cnJlbnRDb2xvciIgc3Ryb2tlLXdpZHRoPSIxLjUiIHN0cm9rZS1saW5lY2FwPSJyb3VuZCIgc3Ryb2tlLWxpbmVqb2luPSJyb3VuZCI+CiAgPGNpcmNsZSBjeD0iMTIiIGN5PSIxMiIgcj0iMyIvPgogIDxwYXRoIGQ9Im0xMiA5IDAgNSIvPgogIDxwYXRoIGQ9Im0xMiAxNSAwIDUiLz4KICA8cGF0aCBkPSJtOSA5IDMgMyIvPgogIDxwYXRoIGQ9Im0xNSA5LTMgMyIvPgogIDxwYXRoIGQ9Im05IDE1IDMgMyIvPgogIDxwYXRoIGQ9Im0xNSAxNUwzIDMiLz4KPC9zdmc+
version: 1.0.0
description: AIä»£ç†ç®¡é“æ’ä»¶ï¼Œè®©AIå“åº”ä»¥ä»£ç†æ¨¡å¼è¿›è¡Œå¤šæ­¥éª¤åˆ†æå’Œå·¥å…·ä½¿ç”¨ã€‚
"""

from pydantic import BaseModel, Field
from typing import Optional, Dict, Any
import logging
import json
from fastapi import Request

from open_webui.utils.chat import generate_chat_completion

logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

class Pipe:
    class Valves(BaseModel):
        priority: int = Field(
            default=0, description="Priority level for the pipe operations."
        )
        enable_agent_mode: bool = Field(
            default=True, description="Enable agent mode for all responses."
        )
        pass

    def __init__(self):
        self.valves = self.Valves()
        pass

    async def pipe(
        self,
        body: dict,
        __user__: Optional[dict] = {},
        __event_emitter__=None,
        __event_call__=None,
        __model__=None,
        __request__: Request = None,
    ) -> Optional[dict]:
        """
        AI Agent Pipe - Transform LLM responses into agent-style multi-step analysis
        """
        logger.info("AI Agent Pipe processing response")

        if not self.valves.enable_agent_mode:
            return body

        # è·å–åŸå§‹å“åº”
        messages = body.get("messages", [])
        if not messages:
            return body

        # è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯å’ŒAIå“åº”
        user_message = None
        ai_response = None

        for msg in reversed(messages):
            if msg.get("role") == "user" and not user_message:
                user_message = msg.get("content", "")
            elif msg.get("role") == "assistant" and not ai_response:
                ai_response = msg.get("content", "")

        if not user_message or not ai_response:
            return body

        # ç³»ç»Ÿæç¤ºï¼šè®©AIé‡æ–°åˆ†æå¹¶ä»¥ä»£ç†æ¨¡å¼æ ¼å¼åŒ–å“åº”
        system_prompt = """
ä½ æ˜¯ä¸€ä¸ªAIä»£ç†åˆ†æå™¨ã€‚ä½ çš„ä»»åŠ¡æ˜¯å°†æ™®é€šçš„AIå“åº”è½¬æ¢ä¸ºç»“æ„åŒ–çš„ä»£ç†å¼åˆ†ææ ¼å¼ã€‚

è¯·åˆ†æç”¨æˆ·çš„é—®é¢˜å’ŒAIçš„åŸå§‹å“åº”ï¼Œç„¶åä»¥JSONæ ¼å¼é‡æ–°ç»„ç»‡ï¼š

{
  "original_response": "åŸå§‹AIå“åº”",
  "agent_analysis": {
    "problem_identification": "é—®é¢˜è¯†åˆ«",
    "step_by_step_reasoning": ["æ­¥éª¤1", "æ­¥éª¤2", "æ­¥éª¤3"],
    "tool_recommendations": ["å·¥å…·1", "å·¥å…·2"],
    "solution_summary": "è§£å†³æ–¹æ¡ˆæ€»ç»“"
  }
}

å¦‚æœåŸå§‹å“åº”å·²ç»æ˜¯ç»“æ„åŒ–çš„ï¼Œä¿æŒå…¶ç»“æ„ä½†æ·»åŠ ä»£ç†åˆ†æå±‚ã€‚
        """

        analysis_prompt = f"""
ç”¨æˆ·é—®é¢˜ï¼š{user_message}

AIåŸå§‹å“åº”ï¼š{ai_response}

è¯·å°†ä¸Šè¿°å†…å®¹è½¬æ¢ä¸ºä»£ç†å¼åˆ†ææ ¼å¼ã€‚
        """

        try:
            # è°ƒç”¨LLMè¿›è¡Œä»£ç†å¼åˆ†æ
            response = await generate_chat_completion(
                model=__model__,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": analysis_prompt}
                ],
                user=__user__,
            )

            # è§£æåˆ†æç»“æœ
            analysis_content = response.get("choices", [{}])[0].get("message", {}).get("content", "")

            try:
                analysis_result = json.loads(analysis_content)

                # æ„å»ºå¢å¼ºçš„å“åº”
                enhanced_response = f"""
## ğŸ¤– AIä»£ç†åˆ†æç»“æœ

### ğŸ“ åŸå§‹å“åº”
{analysis_result.get('original_response', ai_response)}

### ğŸ” ä»£ç†åˆ†æ

**é—®é¢˜è¯†åˆ«ï¼š**
{analysis_result.get('agent_analysis', {}).get('problem_identification', 'æ— æ³•è§£æ')}

**é€æ­¥æ¨ç†ï¼š**
{chr(10).join(f"{i+1}. {step}" for i, step in enumerate(analysis_result.get('agent_analysis', {}).get('step_by_step_reasoning', [])))}

**æ¨èå·¥å…·ï¼š**
{chr(10).join(f"â€¢ {tool}" for tool in analysis_result.get('agent_analysis', {}).get('tool_recommendations', []))}

**è§£å†³æ–¹æ¡ˆæ€»ç»“ï¼š**
{analysis_result.get('agent_analysis', {}).get('solution_summary', 'æ— æ³•è§£æ')}
                """

                # æ›´æ–°æ¶ˆæ¯ä¸­çš„AIå“åº”
                for msg in messages:
                    if msg.get("role") == "assistant":
                        msg["content"] = enhanced_response
                        break

                body["messages"] = messages

            except json.JSONDecodeError:
                # å¦‚æœè§£æå¤±è´¥ï¼Œæ·»åŠ ç®€å•çš„ä»£ç†æ ¼å¼
                enhanced_response = f"""
## ğŸ¤– AIä»£ç†å“åº”

### åŸå§‹å›ç­”
{ai_response}

### ä»£ç†åˆ†æ
æ­¤å“åº”å·²é€šè¿‡AIä»£ç†ç®¡é“å¤„ç†ï¼Œæä¾›å¤šè§’åº¦åˆ†æå’Œå·¥å…·å»ºè®®ã€‚
                """

                for msg in messages:
                    if msg.get("role") == "assistant":
                        msg["content"] = enhanced_response
                        break

                body["messages"] = messages

        except Exception as e:
            logger.error(f"Error in AI Agent Pipe: {str(e)}")
            # å¦‚æœå‡ºé”™ï¼Œè¿”å›åŸå§‹body
            pass

        return body